{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e12659cebf8d4d198e1c2822066284d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4181d835956e4ff586a03e3256f2f5b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a0427edcf62c42b4bffc8c8eb66c7199",
              "IPY_MODEL_3fde1180dc444d54b2a8152fbcde948e",
              "IPY_MODEL_dd68e4e509f44650bee577007f73a03f"
            ]
          }
        },
        "4181d835956e4ff586a03e3256f2f5b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0427edcf62c42b4bffc8c8eb66c7199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2e02ad2a28043f2a3472568e45b6983",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a31088c4423a49a4abf4de9e6553f942"
          }
        },
        "3fde1180dc444d54b2a8152fbcde948e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_46136ec35cf948fe940a2a7d8f86f518",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd7d5809c9f94cb4a90ce90c616ebcef"
          }
        },
        "dd68e4e509f44650bee577007f73a03f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_650e67e8519d40e497779d9550780e93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1999995/? [00:47&lt;00:00, 43997.86it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73738be518a947a8b5f5ad27d4b5f4f3"
          }
        },
        "c2e02ad2a28043f2a3472568e45b6983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a31088c4423a49a4abf4de9e6553f942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46136ec35cf948fe940a2a7d8f86f518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd7d5809c9f94cb4a90ce90c616ebcef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "650e67e8519d40e497779d9550780e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73738be518a947a8b5f5ad27d4b5f4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qwsRxpKeZ-Y",
        "outputId": "a9846fa6-dbde-4198-a2b5-9761212c0cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2021.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download(\"all\")\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz'\n",
        "# Download Datasets\n",
        "!wget -P 'Data/' $URL\n",
        "# Unzip\n",
        "!tar xvzf 'Data/rt-polaritydata.tar.gz' -C 'Data/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Zx45U_elU9",
        "outputId": "61b65171-5269-4036-b064-0fe045c2301b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-18 14:02:49--  https://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 487770 (476K) [application/x-gzip]\n",
            "Saving to: ‘Data/rt-polaritydata.tar.gz’\n",
            "\n",
            "rt-polaritydata.tar 100%[===================>] 476.34K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-01-18 14:02:49 (5.54 MB/s) - ‘Data/rt-polaritydata.tar.gz’ saved [487770/487770]\n",
            "\n",
            "rt-polaritydata.README.1.0.txt\n",
            "rt-polaritydata/rt-polarity.neg\n",
            "rt-polaritydata/rt-polarity.pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_text(path):\n",
        "    \"\"\"Load text data, lowercase text and save to a list.\"\"\"\n",
        "\n",
        "    with open(path, 'rb') as f:\n",
        "        texts = []\n",
        "        for line in f:\n",
        "            texts.append(line.decode(errors='ignore').lower().strip())\n",
        "\n",
        "    return texts\n",
        "\n",
        "# Load files\n",
        "neg_text = load_text('Data/rt-polaritydata/rt-polarity.neg')\n",
        "pos_text = load_text('Data/rt-polaritydata/rt-polarity.pos')\n",
        "\n",
        "# Concatenate and label data\n",
        "texts = np.array(neg_text + pos_text)\n",
        "labels = np.array([0]*len(neg_text) + [1]*len(pos_text))"
      ],
      "metadata": {
        "id": "gVHXKrMuetAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "URL = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\"\n",
        "FILE = \"fastText\"\n",
        "\n",
        "if os.path.isdir(FILE):\n",
        "    print(\"fastText exists.\")\n",
        "else:\n",
        "    !wget -P $FILE $URL\n",
        "    !unzip $FILE/crawl-300d-2M.vec.zip -d $FILE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE_mrCbhetCr",
        "outputId": "f9d032de-d7df-4169-d3f5-dfb8832a0e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-18 14:02:56--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1523785255 (1.4G) [application/zip]\n",
            "Saving to: ‘fastText/crawl-300d-2M.vec.zip’\n",
            "\n",
            "crawl-300d-2M.vec.z 100%[===================>]   1.42G  46.1MB/s    in 34s     \n",
            "\n",
            "2022-01-18 14:03:30 (43.4 MB/s) - ‘fastText/crawl-300d-2M.vec.zip’ saved [1523785255/1523785255]\n",
            "\n",
            "Archive:  fastText/crawl-300d-2M.vec.zip\n",
            "  inflating: fastText/crawl-300d-2M.vec  \n",
            "CPU times: user 955 ms, sys: 168 ms, total: 1.12 s\n",
            "Wall time: 1min 56s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poSHXOtxetE5",
        "outputId": "42b05015-bee4-4a64-f49f-a3715692d2f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "\n",
        "def tokenize(texts):\n",
        "    \"\"\"Tokenize texts, build vocabulary and find maximum sentence length.\n",
        "    \n",
        "    Args:\n",
        "        texts (List[str]): List of text data\n",
        "    \n",
        "    Returns:\n",
        "        tokenized_texts (List[List[str]]): List of list of tokens\n",
        "        word2idx (Dict): Vocabulary built from the corpus\n",
        "        max_len (int): Maximum sentence length\n",
        "    \"\"\"\n",
        "\n",
        "    max_len = 0\n",
        "    tokenized_texts = []\n",
        "    word2idx = {}\n",
        "\n",
        "    # Add <pad> and <unk> tokens to the vocabulary\n",
        "    word2idx['<pad>'] = 0\n",
        "    word2idx['<unk>'] = 1\n",
        "\n",
        "    # Building our vocab from the corpus starting from index 2\n",
        "    idx = 2\n",
        "    for sent in texts:\n",
        "        tokenized_sent = word_tokenize(sent)\n",
        "\n",
        "        # Add `tokenized_sent` to `tokenized_texts`\n",
        "        tokenized_texts.append(tokenized_sent)\n",
        "\n",
        "        # Add new token to `word2idx`\n",
        "        for token in tokenized_sent:\n",
        "            if token not in word2idx:\n",
        "                word2idx[token] = idx\n",
        "                idx += 1\n",
        "\n",
        "        # Update `max_len`\n",
        "        max_len = max(max_len, len(tokenized_sent))\n",
        "\n",
        "    return tokenized_texts, word2idx, max_len\n",
        "\n",
        "def encode(tokenized_texts, word2idx, max_len):\n",
        "    \"\"\"Pad each sentence to the maximum sentence length and encode tokens to\n",
        "    their index in the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        input_ids (np.array): Array of token indexes in the vocabulary with\n",
        "            shape (N, max_len). It will the input of our CNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    input_ids = []\n",
        "    for tokenized_sent in tokenized_texts:\n",
        "        # Pad sentences to max_len\n",
        "        tokenized_sent += ['<pad>'] * (max_len - len(tokenized_sent))\n",
        "\n",
        "        # Encode tokens to input_ids\n",
        "        input_id = [word2idx.get(token) for token in tokenized_sent]\n",
        "        input_ids.append(input_id)\n",
        "    \n",
        "    return np.array(input_ids)"
      ],
      "metadata": {
        "id": "yP_BJFzLetIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm_notebook\n",
        "\n",
        "def load_pretrained_vectors(word2idx, fname):\n",
        "    \"\"\"Load pretrained vectors and create embedding layers.\n",
        "    \n",
        "    Args:\n",
        "        word2idx (Dict): Vocabulary built from the corpus\n",
        "        fname (str): Path to pretrained vector file\n",
        "\n",
        "    Returns:\n",
        "        embeddings (np.array): Embedding matrix with shape (N, d) where N is\n",
        "            the size of word2idx and d is embedding dimension\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Loading pretrained vectors...\")\n",
        "    fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "\n",
        "    # Initilize random embeddings\n",
        "    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), d))\n",
        "    embeddings[word2idx['<pad>']] = np.zeros((d,))\n",
        "\n",
        "    # Load pretrained vectors\n",
        "    count = 0\n",
        "    for line in tqdm_notebook(fin):\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        word = tokens[0]\n",
        "        if word in word2idx:\n",
        "            count += 1\n",
        "            embeddings[word2idx[word]] = np.array(tokens[1:], dtype=np.float32)\n",
        "\n",
        "    print(f\"There are {count} / {len(word2idx)} pretrained vectors found.\")\n",
        "\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "ppuDTlL1e4Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize, build vocabulary, encode tokens\n",
        "print(\"Tokenizing...\\n\")\n",
        "tokenized_texts, word2idx, max_len = tokenize(texts)\n",
        "input_ids = encode(tokenized_texts, word2idx, max_len)\n",
        "\n",
        "# Load pretrained vectors\n",
        "embeddings = load_pretrained_vectors(word2idx, \"fastText/crawl-300d-2M.vec\")\n",
        "embeddings = torch.tensor(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "e12659cebf8d4d198e1c2822066284d1",
            "4181d835956e4ff586a03e3256f2f5b4",
            "a0427edcf62c42b4bffc8c8eb66c7199",
            "3fde1180dc444d54b2a8152fbcde948e",
            "dd68e4e509f44650bee577007f73a03f",
            "c2e02ad2a28043f2a3472568e45b6983",
            "a31088c4423a49a4abf4de9e6553f942",
            "46136ec35cf948fe940a2a7d8f86f518",
            "fd7d5809c9f94cb4a90ce90c616ebcef",
            "650e67e8519d40e497779d9550780e93",
            "73738be518a947a8b5f5ad27d4b5f4f3"
          ]
        },
        "id": "XrTjAQ48e4GI",
        "outputId": "1dcaa656-ea68-4390-d1a5-d5fb23c9bf40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing...\n",
            "\n",
            "Loading pretrained vectors...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e12659cebf8d4d198e1c2822066284d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 18526 / 20286 pretrained vectors found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler,\n",
        "                              SequentialSampler)\n",
        "\n",
        "def data_loader(train_inputs, val_inputs, train_labels, val_labels,\n",
        "                batch_size=50):\n",
        "    \"\"\"Convert train and validation sets to torch.Tensors and load them to\n",
        "    DataLoader.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data type to torch.Tensor\n",
        "    train_inputs, val_inputs, train_labels, val_labels =\\\n",
        "    tuple(torch.tensor(data) for data in\n",
        "          [train_inputs, val_inputs, train_labels, val_labels])\n",
        "\n",
        "    # Specify batch_size\n",
        "    batch_size = 50\n",
        "\n",
        "    # Create DataLoader for training data\n",
        "    train_data = TensorDataset(train_inputs, train_labels)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    # Create DataLoader for validation data\n",
        "    val_data = TensorDataset(val_inputs, val_labels)\n",
        "    val_sampler = SequentialSampler(val_data)\n",
        "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, val_dataloader"
      ],
      "metadata": {
        "id": "hCPzvUyOe4JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train Test Split\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
        "    input_ids, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Load data to PyTorch DataLoader\n",
        "train_dataloader, val_dataloader = \\\n",
        "data_loader(train_inputs, val_inputs, train_labels, val_labels, batch_size=50)"
      ],
      "metadata": {
        "id": "_CD3eJMIfEy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_NLP(nn.Module):\n",
        "    \"\"\"An 1D Convulational Neural Network for Sentence Classification.\"\"\"\n",
        "    def __init__(self,\n",
        "                 pretrained_embedding=None,\n",
        "                 freeze_embedding=False,\n",
        "                 vocab_size=None,\n",
        "                 embed_dim=300,\n",
        "                 filter_sizes=[3, 4, 5],\n",
        "                 num_filters=[100, 100, 100],\n",
        "                 num_classes=2,\n",
        "                 dropout=0.5):\n",
        "        \"\"\"\n",
        "        The constructor for CNN_NLP class.\n",
        "\n",
        "        Args:\n",
        "            pretrained_embedding (torch.Tensor): Pretrained embeddings with\n",
        "                shape (vocab_size, embed_dim)\n",
        "            freeze_embedding (bool): Set to False to fine-tune pretraiend\n",
        "                vectors. Default: False\n",
        "            vocab_size (int): Need to be specified when not pretrained word\n",
        "                embeddings are not used.\n",
        "            embed_dim (int): Dimension of word vectors. Need to be specified\n",
        "                when pretrained word embeddings are not used. Default: 300\n",
        "            filter_sizes (List[int]): List of filter sizes. Default: [3, 4, 5]\n",
        "            num_filters (List[int]): List of number of filters, has the same\n",
        "                length as `filter_sizes`. Default: [100, 100, 100]\n",
        "            n_classes (int): Number of classes. Default: 2\n",
        "            dropout (float): Dropout rate. Default: 0.5\n",
        "        \"\"\"\n",
        "\n",
        "        super(CNN_NLP, self).__init__()\n",
        "        # Embedding layer\n",
        "        if pretrained_embedding is not None:\n",
        "            self.vocab_size, self.embed_dim = pretrained_embedding.shape\n",
        "            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n",
        "                                                          freeze=freeze_embedding)\n",
        "        else:\n",
        "            self.embed_dim = embed_dim\n",
        "            self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                          embedding_dim=self.embed_dim,\n",
        "                                          padding_idx=0,\n",
        "                                          max_norm=5.0)\n",
        "        # Conv Network\n",
        "        self.conv1d_list = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=self.embed_dim,\n",
        "                      out_channels=num_filters[i],\n",
        "                      kernel_size=filter_sizes[i])\n",
        "            for i in range(len(filter_sizes))\n",
        "        ])\n",
        "        # Fully-connected layer and Dropout\n",
        "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"Perform a forward pass through the network.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): A tensor of token ids with shape\n",
        "                (batch_size, max_sent_length)\n",
        "\n",
        "        Returns:\n",
        "            logits (torch.Tensor): Output logits with shape (batch_size,\n",
        "                n_classes)\n",
        "        \"\"\"\n",
        "\n",
        "        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n",
        "        x_embed = self.embedding(input_ids).float()\n",
        "\n",
        "        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n",
        "        # Output shape: (b, embed_dim, max_len)\n",
        "        x_reshaped = x_embed.permute(0, 2, 1)\n",
        "\n",
        "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
        "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
        "\n",
        "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
        "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
        "            for x_conv in x_conv_list]\n",
        "        \n",
        "        # Concatenate x_pool_list to feed the fully connected layer.\n",
        "        # Output shape: (b, sum(num_filters))\n",
        "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
        "                         dim=1)\n",
        "        \n",
        "        # Compute logits. Output shape: (b, n_classes)\n",
        "        logits = self.fc(self.dropout(x_fc))\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "8pyE6kjjfE2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def initilize_model(pretrained_embedding=None,\n",
        "                    freeze_embedding=False,\n",
        "                    vocab_size=None,\n",
        "                    embed_dim=300,\n",
        "                    filter_sizes=[3, 4, 5],\n",
        "                    num_filters=[100, 100, 100],\n",
        "                    num_classes=2,\n",
        "                    dropout=0.5,\n",
        "                    learning_rate=0.01):\n",
        "    \"\"\"Instantiate a CNN model and an optimizer.\"\"\"\n",
        "\n",
        "    assert (len(filter_sizes) == len(num_filters)), \"filter_sizes and \\\n",
        "    num_filters need to be of the same length.\"\n",
        "\n",
        "    # Instantiate CNN model\n",
        "    cnn_model = CNN_NLP(pretrained_embedding=pretrained_embedding,\n",
        "                        freeze_embedding=freeze_embedding,\n",
        "                        vocab_size=vocab_size,\n",
        "                        embed_dim=embed_dim,\n",
        "                        filter_sizes=filter_sizes,\n",
        "                        num_filters=num_filters,\n",
        "                        num_classes=2,\n",
        "                        dropout=0.5)\n",
        "    \n",
        "    # Send model to `device` (GPU/CPU)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    # Instantiate Adadelta optimizer\n",
        "    optimizer = optim.Adadelta(cnn_model.parameters(),\n",
        "                               lr=learning_rate,\n",
        "                               rho=0.95)\n",
        "\n",
        "    return cnn_model, optimizer"
      ],
      "metadata": {
        "id": "qDRTYCS9fLb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\"\"\"\n",
        "\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, optimizer, train_dataloader, val_dataloader=None, epochs=10):\n",
        "    \"\"\"Train the CNN model.\"\"\"\n",
        "    \n",
        "    # Tracking best validation accuracy\n",
        "    best_accuracy = 0\n",
        "\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {\\\n",
        "    'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "\n",
        "        # Tracking time and loss\n",
        "        t0_epoch = time.time()\n",
        "        total_loss = 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Update parameters\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if val_dataloader is not None:\n",
        "            # After the completion of each training epoch, measure the model's\n",
        "            # performance on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Track the best accuracy\n",
        "            if val_accuracy > best_accuracy:\n",
        "                best_accuracy = val_accuracy\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f} | {\\\n",
        "            val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            \n",
        "    print(\"\\n\")\n",
        "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's\n",
        "    performance on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled\n",
        "    # during the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "7eRx7C7cfLgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN-rand: Word vectors are randomly initialized.\n",
        "set_seed(42)\n",
        "cnn_rand, optimizer = initilize_model(vocab_size=len(word2idx),\n",
        "                                      embed_dim=300,\n",
        "                                      learning_rate=0.25,\n",
        "                                      dropout=0.5)\n",
        "train(cnn_rand, optimizer, train_dataloader, val_dataloader, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_o4v4xHfR9f",
        "outputId": "5f9ddae0-1451-491d-eec3-8859a2e3f56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "------------------------------------------------------------\n",
            "   1    |   0.685883   |  0.650875  |   61.67   |   43.00  \n",
            "   2    |   0.628970   |  0.617810  |   65.40   |   42.89  \n",
            "   3    |   0.570185   |  0.582977  |   67.76   |   44.78  \n",
            "   4    |   0.509048   |  0.560992  |   70.02   |   43.75  \n",
            "   5    |   0.431322   |  0.543243  |   72.47   |   44.57  \n",
            "   6    |   0.364034   |  0.531047  |   72.92   |   42.36  \n",
            "   7    |   0.292034   |  0.535552  |   72.47   |   42.35  \n",
            "   8    |   0.236022   |  0.540053  |   72.65   |   42.30  \n",
            "   9    |   0.189231   |  0.539132  |   71.93   |   42.54  \n",
            "  10    |   0.145939   |  0.570638  |   71.20   |   43.54  \n",
            "  11    |   0.125004   |  0.564436  |   74.20   |   43.36  \n",
            "  12    |   0.099392   |  0.560815  |   73.28   |   43.23  \n",
            "  13    |   0.088222   |  0.597943  |   72.65   |   43.04  \n",
            "  14    |   0.073493   |  0.612296  |   73.83   |   47.57  \n",
            "  15    |   0.065616   |  0.610519  |   73.28   |   43.34  \n",
            "  16    |   0.058645   |  0.639983  |   73.65   |   43.13  \n",
            "  17    |   0.045588   |  0.641203  |   73.47   |   43.00  \n",
            "  18    |   0.041450   |  0.646556  |   74.01   |   42.75  \n",
            "  19    |   0.039098   |  0.667892  |   73.74   |   43.94  \n",
            "  20    |   0.030729   |  0.667441  |   75.73   |   42.90  \n",
            "\n",
            "\n",
            "Training complete! Best accuracy: 75.73%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "cnn_static, optimizer = initilize_model(pretrained_embedding=embeddings,\n",
        "                                        freeze_embedding=True,\n",
        "                                        learning_rate=0.25,\n",
        "                                        dropout=0.5)\n",
        "train(cnn_static, optimizer, train_dataloader, val_dataloader, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFCVtZLlfSAU",
        "outputId": "d7cdaef1-ba35-4654-f0db-d6b761eabdb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "------------------------------------------------------------\n",
            "   1    |   0.584872   |  0.470015  |   77.20   |   22.86  \n",
            "   2    |   0.451392   |  0.433366  |   80.56   |   22.81  \n",
            "   3    |   0.395049   |  0.412271  |   81.29   |   22.68  \n",
            "   4    |   0.337329   |  0.405322  |   81.83   |   22.70  \n",
            "   5    |   0.288469   |  0.400671  |   82.20   |   22.70  \n",
            "   6    |   0.231534   |  0.402071  |   82.65   |   22.57  \n",
            "   7    |   0.193418   |  0.411430  |   81.56   |   22.41  \n",
            "   8    |   0.154324   |  0.413964  |   82.20   |   22.49  \n",
            "   9    |   0.118777   |  0.434903  |   82.28   |   22.50  \n",
            "  10    |   0.089448   |  0.443204  |   82.65   |   22.65  \n",
            "  11    |   0.077348   |  0.462383  |   82.39   |   22.70  \n",
            "  12    |   0.061865   |  0.471348  |   82.29   |   22.61  \n",
            "  13    |   0.049411   |  0.483797  |   83.37   |   22.58  \n",
            "  14    |   0.046567   |  0.515852  |   82.02   |   35.64  \n",
            "  15    |   0.035463   |  0.512849  |   81.56   |   22.69  \n",
            "  16    |   0.027633   |  0.527428  |   82.19   |   22.65  \n",
            "  17    |   0.026292   |  0.517071  |   82.74   |   22.54  \n",
            "  18    |   0.022513   |  0.533681  |   83.56   |   22.64  \n",
            "  19    |   0.020043   |  0.544943  |   83.19   |   22.65  \n",
            "  20    |   0.018635   |  0.549201  |   82.29   |   22.61  \n",
            "\n",
            "\n",
            "Training complete! Best accuracy: 83.56%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "cnn_non_static, optimizer = initilize_model(pretrained_embedding=embeddings,\n",
        "                                            freeze_embedding=False,\n",
        "                                            learning_rate=0.25,\n",
        "                                            dropout=0.5)\n",
        "train(cnn_non_static, optimizer, train_dataloader, val_dataloader, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISPgx7xRfLjd",
        "outputId": "733adf63-16e3-4578-81d6-e6fdfb8b3704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "------------------------------------------------------------\n",
            "   1    |   0.584045   |  0.468041  |   77.39   |   58.39  \n",
            "   2    |   0.447597   |  0.428951  |   80.93   |   59.36  \n",
            "   3    |   0.385138   |  0.404394  |   81.56   |   58.14  \n",
            "   4    |   0.323716   |  0.400096  |   82.29   |   57.90  \n",
            "   5    |   0.272988   |  0.395365  |   82.28   |   57.86  \n",
            "   6    |   0.214323   |  0.403277  |   82.56   |   57.75  \n",
            "   7    |   0.174551   |  0.419667  |   81.48   |   57.58  \n",
            "   8    |   0.131929   |  0.422208  |   82.29   |   57.99  \n",
            "   9    |   0.098636   |  0.430448  |   82.11   |   57.89  \n",
            "  10    |   0.072827   |  0.447724  |   82.38   |   58.76  \n",
            "  11    |   0.059485   |  0.464598  |   83.20   |   58.79  \n",
            "  12    |   0.046264   |  0.494073  |   81.65   |   60.25  \n",
            "  13    |   0.037146   |  0.507813  |   83.10   |   58.99  \n",
            "  14    |   0.032602   |  0.519452  |   82.29   |   58.88  \n",
            "  15    |   0.025012   |  0.532525  |   82.56   |   58.59  \n",
            "  16    |   0.019855   |  0.555323  |   82.56   |   58.55  \n",
            "  17    |   0.018060   |  0.553650  |   82.93   |   58.78  \n",
            "  18    |   0.015197   |  0.577588  |   82.83   |   58.47  \n",
            "  19    |   0.013488   |  0.605471  |   82.38   |   58.18  \n",
            "  20    |   0.012300   |  0.583553  |   83.11   |   58.01  \n",
            "\n",
            "\n",
            "Training complete! Best accuracy: 83.20%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, model=cnn_non_static.to(\"cpu\"), max_len=62):\n",
        "    \"\"\"Predict probability that a review is positive.\"\"\"\n",
        "\n",
        "    # Tokenize, pad and encode text\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    padded_tokens = tokens + ['<pad>'] * (max_len - len(tokens))\n",
        "    input_id = [word2idx.get(token, word2idx['<unk>']) for token in padded_tokens]\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    input_id = torch.tensor(input_id).unsqueeze(dim=0)\n",
        "\n",
        "    # Compute logits\n",
        "    logits = model.forward(input_id)\n",
        "\n",
        "    #  Compute probability\n",
        "    probs = F.softmax(logits, dim=1).squeeze(dim=0)\n",
        "\n",
        "    print(f\"This review is {probs[1] * 100:.2f}% positive.\")\n"
      ],
      "metadata": {
        "id": "IyeiTtw2fbLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\"All of friends slept while watching this movie. But I really enjoyed it.\")\n",
        "predict(\"I have waited so long for this movie. I am now so satisfied and happy.\")\n",
        "predict(\"This movie is long and boring.\")\n",
        "predict(\"I don't like the ending.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOIRMlyefbOA",
        "outputId": "54448f6d-9532-4ad1-d36c-da0afdf7b98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This review is 34.72% positive.\n",
            "This review is 92.37% positive.\n",
            "This review is 0.01% positive.\n",
            "This review is 6.63% positive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "2UpQwfUJfbQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skorch\n",
        "from skorch import NeuralNetClassifier\n",
        "from skorch.helper import predefined_split\n",
        "from skorch.callbacks import EarlyStopping, Checkpoint, LoadInitState\n",
        "from skorch.dataset import CVSplit, Dataset\n",
        "\n",
        "# Specify validation set\n",
        "val_dataset = Dataset(val_inputs, val_labels)\n",
        "\n",
        "# Specify callbacks and checkpoints\n",
        "cp = Checkpoint(monitor='valid_acc_best', dirname='exp1')\n",
        "callbacks = [\n",
        "    ('early_stop', EarlyStopping(monitor='valid_acc', patience=5, lower_is_better=False)),\n",
        "    cp\n",
        "]\n",
        "\n",
        "net = NeuralNetClassifier(\n",
        "    # Module\n",
        "    module=CNN_NLP,\n",
        "    module__pretrained_embedding=embeddings,\n",
        "    module__freeze_embedding=False,\n",
        "    module__dropout=0.5,\n",
        "    # Optimizer\n",
        "    criterion=nn.CrossEntropyLoss,\n",
        "    optimizer=optim.Adadelta,\n",
        "    optimizer__lr=0.25,\n",
        "    optimizer__rho=0.95,\n",
        "    # Others\n",
        "    max_epochs=20,\n",
        "    batch_size=50,\n",
        "    train_split=predefined_split(val_dataset),\n",
        "    iterator_train__shuffle=True,\n",
        "    warm_start=False,\n",
        "    callbacks=callbacks,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L50HZ_exBVMi",
        "outputId": "23fa7def-70dd-4853-8ede-78a513b8e4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.0.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "_ = net.fit(np.array(train_inputs), train_labels)\n",
        "\n",
        "valid_acc_best = np.max(net.history[:, 'valid_acc'])\n",
        "print(f\"Training complete! Best accuracy: {valid_acc_best * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je5eJekpBc7J",
        "outputId": "0499f66e-0940-416c-e1f8-a2f55cf6872f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss    cp      dur\n",
            "-------  ------------  -----------  ------------  ----  -------\n",
            "      1        \u001b[36m0.5309\u001b[0m       \u001b[32m0.8022\u001b[0m        \u001b[35m0.4320\u001b[0m     +  57.7598\n",
            "      2        \u001b[36m0.3496\u001b[0m       \u001b[32m0.8154\u001b[0m        \u001b[35m0.4023\u001b[0m     +  57.5342\n",
            "      3        \u001b[36m0.2700\u001b[0m       \u001b[32m0.8257\u001b[0m        \u001b[35m0.3957\u001b[0m     +  57.4825\n",
            "      4        \u001b[36m0.2043\u001b[0m       0.8257        0.4129        57.3886\n",
            "      5        \u001b[36m0.1563\u001b[0m       0.8257        0.4257        57.0315\n",
            "      6        \u001b[36m0.1078\u001b[0m       \u001b[32m0.8313\u001b[0m        0.4560     +  57.4893\n",
            "      7        \u001b[36m0.0854\u001b[0m       0.8154        0.4760        57.3495\n",
            "      8        \u001b[36m0.0589\u001b[0m       0.8182        0.5029        57.3612\n",
            "      9        \u001b[36m0.0442\u001b[0m       0.8172        0.5407        57.8406\n",
            "     10        \u001b[36m0.0320\u001b[0m       0.8238        0.5561        57.8681\n",
            "     11        \u001b[36m0.0267\u001b[0m       \u001b[32m0.8322\u001b[0m        0.5847     +  57.9661\n",
            "     12        \u001b[36m0.0214\u001b[0m       0.8163        0.6145        57.6925\n",
            "     13        \u001b[36m0.0187\u001b[0m       0.8247        0.6256        57.1609\n",
            "     14        \u001b[36m0.0161\u001b[0m       0.8304        0.6475        57.0978\n",
            "     15        \u001b[36m0.0127\u001b[0m       0.8266        0.6525        57.6286\n",
            "Stopping since valid_acc has not improved in the last 5 epochs.\n",
            "Training complete! Best accuracy: 83.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = [0.5309,.3496,.2700,.2043,.1563,.1078,.0854,.0589,.0442,.0320,.0267,.0214,.0187,.0161,.0127]\n",
        "valid_loss = [0.4320,0.4023,.3957,.4129,.4257,.4560,.4760,.5029,.5407,.5561,.5847,.6145,.6256,.6475,.6525]\n",
        "epoch = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "plt.plot(epoch, train_loss)\n",
        " \n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Model loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "V8hf2apHBovw",
        "outputId": "82510d49-2b58-41e1-b1e3-ee3bdc61cc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = [0.5309,.3496,.2700,.2043,.1563,.1078,.0854,.0589,.0442,.0320,.0267,.0214,.0187,.0161,.0127]\n",
        "valid_acc = [0.8022,0.8154,.8257,.8257,.8257,.8313,.8154,.8182,.8172,.8238,.8322,.8163,.8247,.8304,.8266]\n",
        "epoch = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "plt.plot(epoch, valid_acc,label= \"validation\")\n",
        "\n",
        " \n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Model accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "qKpn-v5ZDUNc",
        "outputId": "cb1573f3-cffe-42f8-c5a1-13b28b8a8251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyU9bX48c/JHiCZAAlbJsgqhCURDGhr0SouFPdWBaq1WJfe1qXttbe1rbVea297f7e1rfdau7pWRepKlYJLUYtrwk4CCLJkgYSwJYEQsp3fH/MEh5BlJpnJbOf9es2LyTPP88yZTJgz3+95vt+vqCrGGGOMr+JCHYAxxpjIYonDGGOMXyxxGGOM8YslDmOMMX6xxGGMMcYvljiMMcb4xRKHMZ0QkVEioiKS4MO+C0VkZV/EZUyoWeIwUUFEdopIo4hkttu+xvnwHxWayIyJPpY4TDTZASxo+0FEpgL9QhdOePClxWSMPyxxmGjyJHC9189fBZ7w3kFEXCLyhIhUi8guEblbROKcx+JF5Jcisk9EtgMXd3DsX0Rkj4hUiMj9IhLvS2Ai8jcRqRSRGhF5R0Qmez2WKiK/cuKpEZGVIpLqPPY5EXlPRA6JSJmILHS2vyUiN3md44SuMqeVdauIbAW2Ott+65yjVkRWicgsr/3jReSHIvKJiNQ5j+eIyEMi8qt2r2WJiHzHl9dtopMlDhNNPgDSRSTX+UCfD/y13T7/C7iAMcA5eBLNDc5jNwOXANOAAuCqdsc+BjQD45x9LgRuwjf/AMYDQ4DVwFNej/0SOB34LDAI+B7QKiKnOMf9L5AFnAas9fH5AK4AzgAmOT8XOucYBDwN/E1EUpzH/h1Pa20ukA58DagHHgcWeCXXTOB853gTq1TVbnaL+BuwE88H2t3Az4E5wOtAAqDAKCAeaAQmeR33deAt5/4/gX/zeuxC59gEYChwDEj1enwBsMK5vxBY6WOsGc55XXi+vB0F8jvY7wfAi52c4y3gJq+fT3h+5/zndRPHwbbnBbYAl3ey3ybgAuf+bcDSUL/fdgvtzfo+TbR5EngHGE27biogE0gEdnlt2wVkO/dHAGXtHmtzinPsHhFp2xbXbv8OOa2fnwFX42k5tHrFkwykAJ90cGhOJ9t9dUJsIvJd4EY8r1PxtCzaLibo6rkeB67Dk4ivA37bi5hMFLCuKhNVVHUXniL5XOCFdg/vA5rwJIE2I4EK5/4ePB+g3o+1KcPT4shU1Qznlq6qk+nel4HL8bSIXHhaPwDixNQAjO3guLJOtgMc4cTC/7AO9jk+9bVTz/gecA0wUFUzgBonhu6e66/A5SKSD+QCL3Wyn4kRljhMNLoRTzfNEe+NqtoCLAZ+JiJpTg3h3/m0DrIYuENE3CIyELjL69g9wGvAr0QkXUTiRGSsiJzjQzxpeJLOfjwf9v/ldd5W4BHgAREZ4RSpPyMiyXjqIOeLyDUikiAig0XkNOfQtcAXRaSfiIxzXnN3MTQD1UCCiNyDp8XR5s/AT0VkvHjkichgJ8ZyPPWRJ4HnVfWoD6/ZRDFLHCbqqOonqlrUycO34/m2vh1YiafI+4jz2J+A5cA6PAXs9i2W64EkoARPfeA5YLgPIT2Bp9urwjn2g3aPfxfYgOfD+QDw30CcqpbiaTnd6WxfC+Q7x/waT72mCk9X0lN0bTmwDPjYiaWBE7uyHsCTOF8DaoG/AKlejz8OTMWTPEyME1VbyMkY0zURORtPy+wUtQ+NmGctDmNMl0QkEfgW8GdLGgYscRhjuiAiucAhPF1yvwlxOCZMWFeVMcYYv1iLwxhjjF9iYgBgZmamjho1KtRhGGNMRFm1atU+Vc1qvz0mEseoUaMoKurs6kxjjDEdEZFdHW23ripjjDF+scRhjDHGL5Y4jDHG+CUmahwdaWpqory8nIaGhlCHEhVSUlJwu90kJiaGOhRjTJDFbOIoLy8nLS2NUaNG4TVNtukBVWX//v2Ul5czevToUIdjjAmymO2qamhoYPDgwZY0AkBEGDx4sLXejIkRMZs4AEsaAWS/S2NiR0wnDmNMaO0/fIwXVpeHOgzjJ0scEWLAgAEA7N69m6uuuqrDfT7/+c93O9DxN7/5DfX19cd/njt3LocOHQpcoMb44YHXP+bfF69j574j3e9swoYljggzYsQInnvuuR4f3z5xLF26lIyMjECEZoxf6hubeXntbgDWlduXl0hiiSNE7rrrLh566KHjP997773cf//9zJ49m+nTpzN16lRefvnlk47buXMnU6ZMAeDo0aPMnz+f3NxcrrzySo4e/XRFz2984xsUFBQwefJkfvKTnwDw4IMPsnv3bs4991zOPfdcwDMdy759+wB44IEHmDJlClOmTOE3v/nN8efLzc3l5ptvZvLkyVx44YUnPI8xPfXq+j0cPtYMwPrymhBHY/wRs5fjevvPvxdTsrs2oOecNCKdn1w6udPH582bx7e//W1uvfVWABYvXszy5cu54447SE9PZ9++fZx55plcdtllnRaeH374Yfr168emTZtYv34906dPP/7Yz372MwYNGkRLSwuzZ89m/fr13HHHHTzwwAOsWLGCzMzME861atUqHn30UT788ENUlTPOOINzzjmHgQMHsnXrVp555hn+9Kc/cc011/D8889z3XXXBeC3ZGLZosIyxmT1x5WayHprcUQUa3GEyLRp09i7dy+7d+9m3bp1DBw4kGHDhvHDH/6QvLw8zj//fCoqKqiqqur0HO+8887xD/C8vDzy8vKOP7Z48WKmT5/OtGnTKC4upqSkpMt4Vq5cyZVXXkn//v0ZMGAAX/ziF/nXv/4FwOjRoznttNMAOP3009m5c2cvX72JdVur6li16yDzZ+SQ785gY0UtzS2toQ7L+MhaHNBlyyCYrr76ap577jkqKyuZN28eTz31FNXV1axatYrExERGjRrVo7ERO3bs4Je//CWFhYUMHDiQhQsX9mqMRXJy8vH78fHxYdtV1dTSyl9W7uCq091kDkju/gATMosKy0iMF7443c2/tlbz2Hs72VZ9mInD0kMdmvGBtThCaN68eSxatIjnnnuOq6++mpqaGoYMGUJiYiIrVqxg164OZzQ+7uyzz+bpp58GYOPGjaxfvx6A2tpa+vfvj8vloqqqin/84x/Hj0lLS6Ouru6kc82aNYuXXnqJ+vp6jhw5wosvvsisWbMC+GqD77F3d/KLf2zm+VV2eWc4O9bcwgury7lg0lAyByST5/ZcnLG+zOockcJaHCE0efJk6urqyM7OZvjw4Vx77bVceumlTJ06lYKCAiZOnNjl8d/4xje44YYbyM3NJTc3l9NPPx2A/Px8pk2bxsSJE8nJyeGss846fswtt9zCnDlzGDFiBCtWrDi+ffr06SxcuJCZM2cCcNNNNzFt2rSI6ZbaW9fAb9/cClihNdy9VlzFwfom5s0YCcDowf1JS05gbfkhrpmRE+LojC9iYs3xgoICbT++YdOmTeTm5oYoougUyt/pnYvXsWRdBZOGp7P/SCMrv39eSOIw3bv2zx+wc189//reucTFyfFtNUebeOX2yGrlRjsRWaWqBe23W1eViXirdh3k+dXl3Pi5McydOpzyg0fZf/hYqMMyHSjdX8+72/Yzb0bO8aQBkOfOYPOeOhqaWkIYnfGVJQ4T0VpalXuXFDM0PZnbzxv3aX95hXVXhaNni0qJE7i6wH3C9ny3i+ZWZdOewF4Wb4IjphNHLHTT9ZVQ/S4XF5WxoaKGH87NpX9yAlPdLkSs0BqOmlta+VtROZ+fMIThrtQTHjue8GOwPlXb0MT/LN/MnprwvFqxI0FNHCIyR0S2iMg2Ebmrg8dHisgKEVkjIutFZK6zfaaIrHVu60TkSl/P6auUlBT2799vySMA2tbjSElJ6dPnralv4n+Wb2HGqIFclj8CgAHJCYzNGmADysLQii3V7K07xrwOCuDDXSlkDkiOyalHfvP6Vh5a8QkLHymktqEp1OH4JGhXVYlIPPAQcAFQDhSKyBJV9R6JdjewWFUfFpFJwFJgFLARKFDVZhEZDqwTkb8D6sM5feJ2uykvL6e6uroXr9K0aVsBsC/9+o2POVTfyL2XzTxhdH2e28U7H+9DVW269zDybGEpWWnJnDdxyEmPiQj5blfMtTi27a3jifd3MnP0IFbvOsg3/7qaR2+YQWJ8eHcGBfNy3JnANlXdDiAii4DLAe8PeQXaRvy4gN0AqlrvtU+Ks5+v5/RJYmKirVYXwTZX1vLkB7v48hkjmTzCdcJj+e4MXlhdwZ6aBkZkpHZyBtOXKmsa+OfmvXz9nLGdfijmuTP455a91DU0kZYS/UsQqyr3vbKJ1KR4Hr52Om9u3sv3nlvPj17cwH9/KS+sv/QEM61lA2VeP5c727zdC1wnIuV4Whu3tz0gImeISDGwAfg3VW328Zxtx98iIkUiUmStiuiiqvzk5WLSUhK484IJJz2e5/YkEuuuCh/PrSqjVWF+F+M08nJcqMKGGLmw4Z+b9/LOx9V8a/Z4Bg9I5pqCHO44bxyLi8p5aMW2UIfXpVC3hxYAj6mqG5gLPCkicQCq+qGqTgZmAD8QEb860FX1j6paoKoFWVlZAQ/chM4r6/fw4Y4DfPfCCQzsn3TS47nD00mMF9ZagTwstLYqzxaV8dmxgzllcP9O98uPoQJ5Y3MrP32lhDFZ/bn+M6OOb//OBafyxWnZ/PK1j3lpTUXoAuxGMBNHBeD99cLtbPN2I7AYQFXfx9MtdcK0raq6CTgMTPHxnCaK1Tc2819LNzF5RDoLZo7scJ+UxHgmDku3FkeYePeTfZQdONphUdzboP5J5AxKjYn37bH3drBzfz0/vmQSSQmffgyLCL/4Uh5njhnEfzy3jg+27w9hlJ0LZuIoBMaLyGgRSQLmA0va7VMKzAYQkVw8iaPaOSbB2X4KMBHY6eM5TRR7aMU29tQ08J+XTSY+rvM+4Dy3iw3lNbS22lVzobaosIyMfolcNHlYt/vmuTNYF+Utxeq6Yzz45jbOmziEcyecfKFAUkIcf7iugJGD+nHLE0Vs23vy3HKhFrTE4dQkbgOWA5vwXD1VLCL3ichlzm53AjeLyDrgGWCheq6P/RyeK6nWAi8C31TVfZ2dM1ivwYSXXfuP8Kd3dnDFaSMoGDWoy33z3RnUHWtmx35bkjSU9h8+xmvFlVw5LZuUxPhu9893u6g4FN0j/3+5fAsNTS3cfXHn0/O4+iXy2A0zSUqIY+GjhVTXhdfvI6iTHKrqUjxFb+9t93jdLwHO6uC4J4EnfT2niQ0/faWExHjhB3O7nw8rL+fTAvnYrAHBDs104sU1FTS1KPNndNyt2J73QMBzO7hsN9JtKK9h8aoybvrcaMZ083eZM6gff/nqDOb98X1ueryQRbd8htSk7pNvXwh1cdwYn6zYspc3Nu3l9tnjGZre/XUS47IGkJoYH/XdHuFMVXnmo1KmjcxgwrA0n46Zku0Z+R+NAwFVlXv/XsygfkncPnu8T8fk52Tw4PxprK+o4VuL1tASJl2vljhM2DvW3MJ9fy9hTGZ/vnaWb2NvEuLjmJJtBfJQWrXrIJ9UH2GBj60N8Iz8H5c1gHVl0fe+LVm3m1W7DvIfF00g3Y9xKhdOHsY9l0zitZIqfvbqpiBG6DtLHCbsPbJyJzv2HeGeS0+8AqU7ee4MinfX0mRLkobEMx+V0T8pnovzhvt1XJ47g/XlNVE1HVB9YzO/+MdmJo9I5+oC/9ccueGs0XztrNE88u4OHn13RxAi9I8lDhPWqmob+N9/buX83KF8voMrULqS53ZxrLmVLZXhd1VKtKttaOLVDbu57LRs+if7V0o9LcfF/iONVByKnEn/uvP7t7ezp6aBe7u5GrArP7o4lwsnDeW+V0p4rbgywBH6xxKHCWs/X7qJ5lblx5f4v0DUaTmxM6As3Ly8djcNTa0smOn/t+tomym3/GA9f3j7Ey7NH8GMbq4G7Ep8nPDb+dPIc2dwx6I1Ie3Os8RhwlbhzgO8tHY3t8wa0+WI486MHNSPjH6JVucIgWcLS8kdns7UbFf3O7czcXgaifESNQXyny/djAjc9YWul4L2RWpSPH++voCstGRufLyQsgP13R8UBJY4TFhqafXMRzXClcI3zx3bo3OICFOzXayLkm+ukWJjRQ0bK2pZMDOnRxP1JSfEkzs8PSrWVPlg+35e3bCHfztnLNkBmnAzKy2ZRxfOpLG5lRseK6Smvu+nYrfEYcLS0x+VUrKnlh9enEu/pJ4PN8p3Z/BxVR1HG21J0r7yzEelJCfEcXl+h/OP+iTP7WJjRWSP/G9pVf7z7yWMcKXw9bN79uWnM+OGDOCP1xewa/8Rvv7XIo419+3ftyUOE3YOHmnkV69t4cwxg7h4qn9X5LSX53bR0qqU7In8b6+RoL6xmSVrd3Px1OG4+vV8avQ8Z+T/9n2RO/L/2cIyNu2p5Qdzc4MycO/MMYP5n6vy+WD7Ae56fkOfXoVmicOEnV+9voW6hmbuvWxyr9ckyHcK5DYQsG+8un4Pdceau53QsDttM+VG6niOmqNN/PK1LcwcNYhL/Lwc2R9XTMvmuxeeyotrKvj1G1uD9jztWeIwYaV4dw1Pf1jKV848hYnD0rs/oBtD01MYmp5sBfI+8mxhGWMy+zNzdM+vHgJPV0y/pPiIfd8efHMrB+sbuefSSUFfkOnWc8dxTYGbB9/cyuKisu4PCABLHCZsqCr3Likmo18S3zn/1ICdt21AmQmurVV1FO06yLwZPSuKe4uPE6ZE6IUN2/bW8fh7O5k/I4cpPbiqzF8iws+unMqs8Zn88IUNrNy6L+jPaYnDhI2X1+6mcOdBvnfRhF71j7d3Wk4G2/cdoeZo3199EkueLSwjMV740umBWXs+3+2iZE8tjc2RM/L/+HKwifHceeHJq1MGS2J8HA9dO51xQwbwjb+uCvqgV0scJiwcPuZZoCnP7eKaHkzJ0JW2pWQ3ROC310hxrLmF51eXc8GkoWQOSA7IOfPcGTQ2t/JxVeSM/F+xxVkO9vzxAfs9+Co9JZFHFs4gNSmeGx79iKrahqA9lyUOExb+959b2Vt3jHsvm0xcD6dk6ExetlNojdD+8kjwekkVB+ubmOfHhIbdOV4gj5D3zbMc7KaTloPtSyMyUnlk4QxqjjZx4+OFHDnWHJTnscRhQm579WEeWbmDL013M33kwICf39UvkVGD+0VsoTUSLPqojOyMVGaNy+x+Zx/lDEplYL/EiBkI+Ph7nsk42y8H29emZLv4v2uns2lPHbc/s4bmIEzyaYnDhJSnT7iE5IR4vv+F4PUJW4E8eMoO1LNy2z6uKcgJaGtRRJjqzoiIFodnOditnDshq8PlYPvauROGcN/lk9m29zD7DjcG/PyWOExIvblpL29tqebb549nSFr3CzT1VJ7bxZ6aBvbWBa/fN1Y9W1hGnMDVBYEpinvLd7v4uKqO+sbgdLkEyi+Xb+FoUwt3XzIp1KEcd+0Zp7Ds27MY5gr8/ytLHCZkGppauO+VEsYNGcBXPzsqqM/VNhAwUro9IkVzSyt/W1XGOadmMSJAczF5y3Nn0KpQvLs24OcOlLblYBd+dlTYLVPcm+l6umKJw4TMn/+1ndID9dx76WQS44P7pzh5RDpxgtU5AuytLdVU1R5j/szAFcW95TtXxIXrCHJV5T/9XA42GljiMCGx+9BRHlrxCXMmD+Nz4wNXUO1Mv6QETh2aFpEDysLZosJSMgckc97E4PTrD0lPYbgrJWzrU39fv4ciZzlYV2rgxh6Fu+C0Y0yfKztQz/9bvoWmCBkstWPfEVpV+dHF/i/Q1FP57gyWl1SiqkGfBiIWVNY08M/Ne/n6OWOD2mLMc7vCsqV4tLGFny/d1OPlYCOZJY4o8fRHpby6fjfjh6SFOhSfiMBPr5hCzqB+ffaceTkuni0qo+zAUUYO7rvnjVbPrSqjVWFekD8089wZLC+uoqa+KaAzCvTW79/+hD01Dfx2/rQeLwcbqSxxRAFVZdnGSs4al8mTN54R6nDClveAMkscvdPaqjxbVMZnxgxmVKb/qzP6o+19W19xiFnjs4L6XL4qP1jP79/+hEvyhvd6QsdIFNQah4jMEZEtIrJNRO7q4PGRIrJCRNaIyHoRmetsv0BEVonIBuff87yOecs551rnFvqLpkNs697D7Nh3hIsmDwt1KGFtwrA0khLiwrLbI9K898l+yg4cZX4P1hT311SnQB5OdY6f/8OzHOwP5vZdV2s4CVqLQ0TigYeAC4ByoFBElqhqiddudwOLVfVhEZkELAVGAfuAS1V1t4hMAZYD3suJXauqRcGKPdIs21iJCFw4aWioQwlrifFxTBqebgXyAFhUWEpGv8Q++bLiSk1kdGZ/1obJlVUfbt/Pq+v38O3zxwdsOdhIE8wWx0xgm6puV9VGYBFwebt9FGhbdMEF7AZQ1TWqutvZXgykikjfzhgWQZZtrOT0kQMZkh68AXTRIt9ZkrQlgpckDbUDRxp5rbiKK6dlk5IY+JXtOpIfJgXyYC4HG0mCmTiyAe9VRco5sdUAcC9wnYiU42lt3N7Beb4ErFbVY17bHnW6qX4snVweIyK3iEiRiBRVV1f3+EWEu9L99ZTsqWXOFOum8kWeO4P6xhY+qT4c6lAi1gury2lsaWV+ACc07E6eO4Oq2mNBnfHVF4uLyigJ4nKwkSLU4zgWAI+pqhuYCzwpIsdjEpHJwH8DX/c65lpVnQrMcm5f6ejEqvpHVS1Q1YKsrPAoqAXD8uJKAKtv+Cg/J7wHlIU7VWVRYRnTRmYwYVjfXcEXDu/bseYWfvXaFmaMGhjU5WAjQTATRwXgXTlzO9u83QgsBlDV94EUIBNARNzAi8D1qvpJ2wGqWuH8Wwc8jadLLGYtK65k8oj0Pr2sNZKNyRzAgOSEsCq0RpJVuw6ybe9hFvRhawNg0nAX8XES0vftteIq9h1u5Lbzxsf8OKBgJo5CYLyIjBaRJGA+sKTdPqXAbAARycWTOKpFJAN4FbhLVd9t21lEEkSkLbEkApcAG4P4GsLa3toGVu06yBxrbfgsLk6Ymu2KiBlXw9GiwjL6J8VzcR9/405NindG/ofufXu20DN1/OcCOHV8pApa4lDVZuA2PFdEbcJz9VSxiNwnIpc5u90J3Cwi64BngIWqqs5x44B72l12mwwsF5H1wFo8LZg/Bes1hLvlJVUAVt/wU16Oi017ajnW3BLqUCJKbUMTr6zfzWWnZdM/ue+HgOW7XWyoqMHzEdG3Svd/OnV8rA3260hQ331VXYqn6O297R6v+yXAWR0cdz9wfyenPT2QMUay5RsrGZPVn3FDwmtGznCX786gqUXZvKfu+Ky5pntL1u6moamV+TNCM71GnjuDRYVllB6o55TBwR102N7iouBNHR+JQl0cNz10qL6R97fvZ87kYTHf3+qvvOMDyqy7yh+LCkvJHZ5+/PfX19qet6/HcwR76vhIZIkjQr2xaS8trWrdVD2QnZHK4P5JNhDQD6tLD7Kxopb5M3JC9kVlwrA0khPi+rxAHuyp4yORJY4ItWxjJSNcKUzNDs23v0gmImE742q4+u0bWxnUP4mrTg9dV01ifByTR6T3+fsW7KnjI5Eljgh05Fgz72yt5qIp1k3VU3nuDLbtPcyRY+G9JGk4WF16kLc/ruaWs8eEpCjuLc+dwcaKWppb+mb5gLap468ucAd9sbFIYr+JCPTWlmoam1vtMtxeyM9x0aqwscK6q7rT1tr4ypmnhDoU8nNcHG1qYVsfjfzvq6njI40ljgi0rLiSwf2TKBgVe9M5B0qe1xTrpnPh1NqAT9+3vlg7vi+njo80ljgiTENTC//cVMWFk4fa9eS9kDkgmeyMVCuQdyOcWhsAowf3Jy05oU8Sfl9OHR9pLHFEmPc+2ceRxhabmyoA8nOsQN6VcGttgDPy3903I/+fKSzFldo3U8dHGkscEWbZxkrSkhP47Fib9qC38twZlB04yoEjjaEOJSyFW2ujTZ47g8176mhoCt7If8/U8ZV9OnV8JLHEEUGaW1p5vaSK2blDSEqwt663bCBg58KxtdHmtBwXza3Kpj21QXuOF1aX09SiLLCxGx2yT58I8tHOAxysb7JBfwEyNduFSHgtSRouwrW1AV4F8iC9b6GaOj6SWOKIIMs3VpKSGMfZp0bv+iJ9KS0lkTGZ/a3F0U44tzYAhrtSyByQHLQ6R9vU8aGakysSWOKIEK2tyvLiKs45NYt+SeH3nzlS5bszWFcemhlXw1U4tzbAM/Lfs5RscFocbVPHX5I3IijnjwaWOCLEuvJDVNY2WDdVgOW5XVTXHaMyxEuShotwb220yXNn8En1YQ4HeOT/p1PHjwjr1x9qljgixLLiShLihPMmDg11KFGlbVp1W0rWI9xbG23yclyowoYAtzo+nTreiuJdscQRAVSV5Rsr+ey4TFypiaEOJ6rkDk8nIU5sICCwJkJaG+DpYoTAj/xfVFjKxGFpIZs6PlJY4ogAW6rq2Lm/3uamCoKUxHgmDk+zAjnw2zcjo7UBMKh/Eu6BqQF93zZW1LCxopYFM0fa5KHdsMQRAZZtrEQELphk3VTBkOfOYH15Da2tsVsgX1N6kLe2VHPzrPBvbbTJz8lgXQDnrFpUWEpyQhxXnJYdsHNGK0scEWDZxkpmnDKIrLTkUIcSlfLdLuoamtm5/0ioQwmZ3765lYH9Ern+M+Hf2miT73ZRcego+w8f6/W56hubeXnNbuZOHY6rn3UHd8cSR5jbue8ImyvruMiupgqaYA8oC3dtrY1bzh4bMa0NCOz7tnRDJXXHmm3sho8scYS55cWVAFw02bqpgmX8kAGkJMbF7BTrkdjaAJjijPwPxPu26KNSxmT2Z+ZoW6rAF5Y4wtyy4kqmZrtwD+wX6lCiVkJ8HFNGBG9AWTiL1NYGwIDkBMZlDej1+7Ztbx1Fuw4yL4TrqUcaSxxhrLKmgTWlh2zQXx/Iz8mgeHcNTX20JGm4iNTWRhvPhQ2HejXyf9FHZSTECV+cHrr11CNNUBOHiMwRkS0isk1E7urg8ZEiskJE1ojIehGZ62y/QERWicgG59/zvI453VUJmngAABrySURBVNm+TUQelCj+ivBaSVs3lSWOYMtzu2hoauXjqrpQh9JnIrm10SY/x8W+w41UHDrao+OPNbfwwpoKLpg01C4+8UPQEoeIxAMPAV8AJgELRGRSu93uBhar6jRgPvA7Z/s+4FJVnQp8FXjS65iHgZuB8c5tTrBeQ6gt21jJuCEDGDdkQKhDiXr5MVggj/TWBvS+QP56SRUHjjQy36ZP94tPiUNEXhCRi0XEn0QzE9imqttVtRFYBFzebh8F0p37LmA3gKquUdXdzvZiIFVEkkVkOJCuqh+op236BHCFHzFFjANHGvlwxwEb9NdHThncD1dqYswMBIyG1gZA7vA0EuOlxwXyZwvLyM5I5XPjbGE0f/iaCH4HfBnYKiK/EJEJPhyTDZR5/VzubPN2L3CdiJQDS4HbOzjPl4DVqnrMOb68m3NGhTc2VdHSqlbf6CMiQp7bFdABZeEsGlobAMkJ8eQOT2d9D963sgP1/GvrPq4pyCE+Lmp7vIPCp8Shqm+o6rXAdGAn8IaIvCciN4hIb0bLLAAeU1U3MBd40rtVIyKTgf8Gvu7viUXkFhEpEpGi6urqXoQYGss3VpKdkcrkEend72wCIs/tYktVcJckDQfR0tpok+d2sbHC/5H/i4vKiBO4usCK4v7yuetJRAYDC4GbgDXAb/Ekktc7OaQC8B5N43a2ebsRWAygqu8DKUCm83xu4EXgelX9xOuc3u9yR+fEOd8fVbVAVQuysiJr4aPDx5r519Z9zJkyzC4P7EN57gxaWpXi3cFbkjQcREtro02eO4O6Y81s3+f7yP/mllYWF5VxzqlZjMhIDWJ00cnXGseLwL+AfniK1pep6rOqejvQWeW2EBgvIqNFJAlP8XtJu31KgdnOc+TiSRzVIpIBvArcparvtu2sqnuAWhE507ma6nrgZR9fa8RYsXkvjS2t1k3Vxz4tkEdvnSPaWhvQs/ftrS3VVNUeY55Nn94jvrY4HlTVSar6c+fD+zhVLejoAFVtBm4DlgOb8Fw9VSwi94nIZc5udwI3i8g64BlgoVP0vg0YB9wjImud2xDnmG8Cfwa2AZ8A//D51UaIZcWVZA5IZvrIgaEOJaYMc6UwJC05qq+sirbWBsC4IQPolxTv1/u2qLCMzAHJzM4d0v3O5iS+fuWYJCJrVPUQgIgMBBao6u+6OkhVl+Ipentvu8frfglwVgfH3Q/c38k5i4ApPsYdcRqaWlixeS9XTMu2gl0IeGZcjc4WR1tr4/tzJkZNawMgPk6YMsLFWh/ft6raBlZs2cvNs8aQGG9joHvC19/azW1JA0BVD+IZS2ECbOXWfdQ3tthluCGS73axfd8Rao42hTqUgIvG1kabPLeLkj21NDZ3P/L/uVXltLSqTWjYC74mjnjvEdrO4L6k4IQU25YVV5KeksCZYwaHOpSY1DagbGNFdHVXRWNtw1t+TgaNzd2P/G9tVRYVlvKZMYMZldm/j6KLPr4mjmXAsyIyW0Rm46lHLAteWLGpqaWVNzZVcX7uUJISrAkdCm1LhkbbTLnR3NoA35eSfX/7fsoOHGX+TGtt9Iavn07fB1YA33BubwLfC1ZQseqjHQc4VN9ka2+EUEa/JE4Z3K9HA8rCVbS3NgByBqUysF9it+/bMx+V4kpNtPnfesmnvyJVbcUzR9TDwQ0nti3bWElqYjxnj4+scSfRJs+dwaqdB0IdRsBEe2sDPCP/p7ozumxxHDjSyGvFVXz5jJGkJMb3YXTRx9dxHONF5DkRKRGR7W23YAcXS1pbleXFlXx+QhapSfZHHUr5bhe7axqoruv9kqRdqWtoYnv14V5NCd6dWGhttMl3u9i69zBHGzse+f/C6nIaW1qtmyoAfP1LehT4CfBr4FzgBmwtj4BaU3aIvXXHbNBfGMjzGlA2Ozc4Ky9urKjhpseLqKxtwD0wlfNzh3J+7lBmjh4U0PpWLLQ22nw68r+GglEnruSnqjxbWMZpORlMHGbT+PSWr3+hqar6JiCquktV7wUuDl5YsWd5cSWJ8cK5E21AUqhNyU4nTmBdkAYCvl5SxTV/eB8RuPviXCYMTeOZj0q57i8fcvpPX+e2p1fz0poKDtU39up5Yqm1AZ4WB9DheI7VpQfZuvcwC6y1ERC+/jUdcyYf3Coit+GZH8oWiQgQVWXZxkrOGpdJekpv5ow0gdAvKYFTh6YFfCCgqvKXlTv42dJNTM128efrCxiSnsJNs8ZwtLGFldv28UZJFW9u3ssr6/cQHycUnDKQCyYNZXbuUEb7efloLLU2AIakpzDcldLhCPJFH5XRPymeS/JGhCCy6ONr4vgWnnmq7gB+iqe76qvBCirWbNpTR+mBer75+bGhDsU48twuXi+pQlUDMtFkU0sr97xczDMflTJn8jB+Pe+0E2pZqUnxXDBpKBdMGkprq7Ku/BBvbtrLG5uquP/VTdz/6ibGZvXn/EmeLq3pIwd2ObNAtI4S706e23XSnFV1DU28sn4PV0wbEVO/i2Dq9rfoDPabp6rfBQ7jqW+YAFpWXEmcwPmTgtOfbvyX585gcVE55QePkjOoX6/OVXO0iVufWs3Kbfv4xufH8h8XTiCuiw/9uDhh2siBTBs5kO9eNIGyA/W8uamKNzbt5ZGVO/jD29sZ1D+JcycM4fzcIcw6NYsB7T4QY6210SbPncHy4ipq6ptw9fO03l9eu5ujTS3MtwkNA6bbxKGqLSLyub4IJlYt31jJjFGDyBxgax6HC+8BZb1JHKX767nhsY/Ytb+e/3dVHtcU+N/HnjOoHwvPGs3Cs0ZT29DEOx9XH2+NPL+6nKT4OM4cO5gLcocwO3coVbUNMdnaAK+ZcisOMcu5rP3ZwjImDks7PrjT9J6vf1VrRGQJ8Dfg+KT3qvpCUKKKIdurD7Olqo57L22/HLsJpQnD0kiKj2N9eU2P+8WLdh7glidX0dKqPHnjGXxmbO+nkUlPSeSSvBFckjeC5pZWinYdPN4a+fHLxfz45WIGJCfEZGsDYKqTHNaX1zBrfBYbK2rYUFHDf1422da2CSBfE0cKsB84z2ubApY4eml5cRUAF9pI1rCSlBBH7oj0HhfIX1pTwfeeW0/2wFT+8tUCxmQF/lqShPg4zhwzmDPHDOZHF0/ik+rDvFFSxTtbq7lymjvmWhsArtRERmf2P/6+PVtYRnJCHFecFpUrTIeMryPHra4RJMuKK8nPybBVyMJQvtvF885Mqr5Oca+q/PqNrTz45lbOGD2I3193OgP79818oGOzBjD2nAF8/ZzYvsgiz+3iw+0HONrYwktrK5g7dfjxeocJDJ8Sh4g8iqeFcQJV/VrAI4ohuw8dZV3ZIb4/Z2KoQzEdyHNn8MT7u9hefZjxQ9O63b+hqYX/eG49f1+3m6tOd/NfV061ySpDIM+dwctrd/Poezuoa2i26dODwNe27Cte91OAK4HdgQ8ntrxWXAnARZPtaqpwdFpO20y5Nd0mjn2Hj3HLE0WsLj3E9+ZM4BvnjLU+9RBpe9/+981tjMnsz8zRg7o5wvjL166q571/FpFngJVBiSiGLCuuZMLQtKD0f5veG5M5gAHJCawrO8RVp7s73e/jqjq+9lgh+w4f4+Frp/OFqcP7MErT3qThLuLjhKNNLcybkWMJPAh62o4eD9jcGL2w//AxPtpxwKZQD2NxccKU7PSTBpR5e/vjar70u/c41tzKs7d8xpJGGEhNiufUoWkkxAlfnN55wjc952uNo44TaxyVeNboMD30xqYqWhVbIjbM5bszePTdnTQ2t55Ur3jyg13cu6SYU4em8ZevFtgFDmHk5lmj2Vt3jKw0GxsVDL52VXVfGTR+WbaxkpGD+pE73H614SzPnUFjSyubK2uPz5rb0qrc/2oJj767k/MmDuHBBdNOGrltQstaGsHl63ocV4qIy+vnDBG5InhhRbfahibe3bafOVOGWf9rmPt0KVnPxHmHjzVz8xNFPPruTr521mj+dH2BJQ0Tc3ytcfxEVY9POamqh/Csz2F6YMXmvTS2tNrylRHAPTCVQf2TWF92iIpDR7nq4fd4++Nq7r9iCvdcOsnn8R3GRBNfvyp1lGDsa1YPLS+uZEhaMtNyMkIdiumGiJDndvGvrft46+NqGhpbeHThDM4+1Zb3NbHL1xZHkYg8ICJjndsDwKruDhKROSKyRUS2ichdHTw+UkRWiMgaEVkvInOd7YOd7YdF5P/aHfOWc861zi2iru5qaGphxeZqLpo8rMsZUk34yHdnUFnbQHJCHM9/87OWNEzM87XVcDvwY+BZPFdXvQ7c2tUBznTsDwEXAOVAoYgsUdUSr93uBhar6sMiMglYCowCGpznm+Lc2rtWVYt8jD2srC49yNGmFs6daB8+keKaGTnUNjRx67njbAZjY/D9qqojwEkthm7MBLap6nYAEVkEXA54Jw4F2hYAduGMRneeb6WIjPPzOcPeB9sPECcwY5SNZo0U2Rmp/OTSyaEOw5iw4etVVa+LSIbXzwNFZHk3h2UDZV4/lzvbvN0LXCci5XhaG7f7Eg/wqNNN9WOJsMuSPti+n6nZLtJsiVhjTITytcaR6VxJBYCqHiQwI8cXAI+pqhuYCzzprG3elWtVdSowy7l9paOdROQWESkSkaLq6uoAhNp7DU0trC09xJljer8ugzHGhIqviaNVRI6vuygio+hgttx2KgDvaSndzjZvNwKLAVT1fTwTKGZ2dVJVrXD+rQOextMl1tF+f1TVAlUtyMoKj3rC6tKDNLa0WuIwxkQ0XxPHj/DUHJ4Ukb8CbwM/6OaYQmC8iIwWkSRgPrCk3T6lwGwAEcnFkzg6bR6ISIKIZDr3E4FLgI0+voaQa6tvFIwaGOpQjDGmx3wtji8TkQLgFmAN8BJwtJtjmkXkNmA5EA88oqrFInIfUKSqS4A7gT+JyHfwtGAWqqoCiMhOPIXzJGeU+oXALmC5kzTigTeAP/n5mkPG6hvGmGjg6ySHNwHfwtPdtBY4E3ifE5eSPYmqLsVT9Pbedo/X/RLgrE6OHdXJaU/3JeZw01bfuOGsUaEOxRhjesXXrqpvATOAXap6LjAN6NlizDHK6hvGmGjha+JoUNUGABFJVtXNwITghRV9rL5hjIkWvo4cL3fGcbwEvC4iB/HUG4yPrL5hjIkWvhbHr3Tu3isiK/CM8l4WtKiijNU3jDHRxO8ZblX17WAEEs2svmGMiSY9XXPc+MHqG8aYaGKJow9YfcMYE00scQSZzU9ljIk2ljiCzOobxphoY4kjyKy+YYyJNpY4gszqG8aYaGOJI4isvmGMiUaWOILI6hvGmGhkiSOIrL5hjIlGljiCyOobxphoZIkjSKy+YYyJVpY4gsTqG8aYaGWJI0isvmGMiVaWOILE6hvGmGhliSMIrL5hjIlmljiCwOobxphoZokjCKy+YYyJZpY4gsDqG8aYaGaJI8CsvmGMiXZBTRwiMkdEtojINhG5q4PHR4rIChFZIyLrRWSus32ws/2wiPxfu2NOF5ENzjkfFBEJ5mvwl9U3jDHRLmiJQ0TigYeALwCTgAUiMqndbncDi1V1GjAf+J2zvQH4MfDdDk79MHAzMN65zQl89D1n9Q1jTLQLZotjJrBNVberaiOwCLi83T4KpDv3XcBuAFU9oqor8SSQ40RkOJCuqh+oqgJPAFcE8TX4zeobxphoF8zEkQ2Uef1c7mzzdi9wnYiUA0uB2304Z3k35wwZq28YY2JBqIvjC4DHVNUNzAWeFJGAxCQit4hIkYgUVVdXB+KU3bL6hjEmFgQzcVQAOV4/u51t3m4EFgOo6vtACpDZzTnd3ZwT53x/VNUCVS3IysryM/SesfqGMSYWBDNxFALjRWS0iCThKX4vabdPKTAbQERy8SSOTpsHqroHqBWRM52rqa4HXg5G8D1h9Q1jTCwIWuJQ1WbgNmA5sAnP1VPFInKfiFzm7HYncLOIrAOeARY6RW9EZCfwALBQRMq9rsj6JvBnYBvwCfCPYL0Gf1h9wxgTKxKCeXJVXYqn6O297R6v+yXAWZ0cO6qT7UXAlMBFGRhW3zDGxIpQF8ejhtU3jDGxwhJHgFh9wxgTKyxxBEBbfeMM66YyxsQASxwB8Gl9Y1CoQzHGmKCzxBEAn9Y3LHEYY6KfJY4A+GD7fqZku0i3+oYxJgZY4uglG79hjIk1ljh6yeobxphYY4mjl6y+YYyJNZY4esnqG8aYWGOJoxesvmGMiUWWOHrB6hvGmFhkiaMXrL5hjIlFljh6weobxphYZImjh6y+YYyJVZY4esjqG8aYWGWJo4esvmGMiVWWOHrI6hvGmFhliaMHrL5hjIllljh6wOobxphYZomjB6y+YYyJZZY4esDqG8aYWGaJw09W3zDGxDpLHH6y+oYxJtYFNXGIyBwR2SIi20Tkrg4eHykiK0RkjYisF5G5Xo/9wDlui4hc5LV9p4hsEJG1IlIUzPg7YvUNY0ysSwjWiUUkHngIuAAoBwpFZImqlnjtdjewWFUfFpFJwFJglHN/PjAZGAG8ISKnqmqLc9y5qrovWLF3xeobxphYF8wWx0xgm6puV9VGYBFwebt9FEh37ruA3c79y4FFqnpMVXcA25zzhZTVN4wxJriJIxso8/q53Nnm7V7gOhEpx9PauN2HYxV4TURWicgtnT25iNwiIkUiUlRdXd3zV+HF6hvGGBP64vgC4DFVdQNzgSdFpLuYPqeq04EvALeKyNkd7aSqf1TVAlUtyMrKCkiwVt8wxpjgJo4KIMfrZ7ezzduNwGIAVX0fSAEyuzpWVdv+3Qu8SB92YVl9wxhjgps4CoHxIjJaRJLwFLuXtNunFJgNICK5eBJHtbPffBFJFpHRwHjgIxHpLyJpzv79gQuBjUF8DcdZfcMYYzyCdlWVqjaLyG3AciAeeERVi0XkPqBIVZcAdwJ/EpHv4KldLFRVBYpFZDFQAjQDt6pqi4gMBV4UkbbYn1bVZcF6Dd6svmGMMR5BSxwAqroUT9Hbe9s9XvdLgLM6OfZnwM/abdsO5Ac+0u5ZfcMYYzxCXRyPGFbfMMYYD0scPrD6hjHGfMoShw+svmGMMZ+yxOEDq28YY8ynLHH4wOobxhjzKUsc3bD6hjHGnMgSRzesvmGMMSeyxNENq28YY8yJLHF0w+obxhhzIkscXbD6hjHGnMwSRxesvmGMMSezxNEFq28YY8zJLHF0weobxhhzsqDOjhvppma7GO5KCXUYxhgTVixxdOHHl0wKdQjGGBN2rKvKGGOMXyxxGGOM8YslDmOMMX6xxGGMMcYvljiMMcb4xRKHMcYYv1jiMMYY4xdLHMYYY/wiqhrqGIJORKqBXaGOo51MYF+og/BRJMUKkRVvJMUKkRVvJMUK4RnvKaqa1X5jTCSOcCQiRapaEOo4fBFJsUJkxRtJsUJkxRtJsUJkxWtdVcYYY/xiicMYY4xfLHGEzh9DHYAfIilWiKx4IylWiKx4IylWiKB4rcZhjDHGL9biMMYY4xdLHMYYY/xiiaMPiUiOiKwQkRIRKRaRb4U6pu6ISLyIrBGRV0IdS3dEJENEnhORzSKySUQ+E+qYuiIi33H+DjaKyDMiEjbLTYrIIyKyV0Q2em0bJCKvi8hW59+BoYzRWyfx/o/zt7BeRF4UkYxQxtimo1i9HrtTRFREMkMRm68scfStZuBOVZ0EnAncKiLhvszgt4BNoQ7CR78FlqnqRCCfMI5bRLKBO4ACVZ0CxAPzQxvVCR4D5rTbdhfwpqqOB950fg4Xj3FyvK8DU1Q1D/gY+EFfB9WJxzg5VkQkB7gQKO3rgPxliaMPqeoeVV3t3K/D88GWHdqoOicibuBi4M+hjqU7IuICzgb+AqCqjap6KLRRdSsBSBWRBKAfsDvE8Rynqu8AB9ptvhx43Ln/OHBFnwbVhY7iVdXXVLXZ+fEDwN3ngXWgk98twK+B7wFhf8WSJY4QEZFRwDTgw9BG0qXf4PlDbg11ID4YDVQDjzpda38Wkf6hDqozqloB/BLPt8s9QI2qvhbaqLo1VFX3OPcrgaGhDMZPXwP+EeogOiMilwMVqrou1LH4whJHCIjIAOB54NuqWhvqeDoiIpcAe1V1Vahj8VECMB14WFWnAUcIr66UEzj1gcvxJLwRQH8RuS60UflOPdfxh/03YwAR+RGebuKnQh1LR0SkH/BD4J5Qx+IrSxx9TEQS8SSNp1T1hVDH04WzgMtEZCewCDhPRP4a2pC6VA6Uq2pbC+45PIkkXJ0P7FDValVtAl4APhvimLpTJSLDAZx/94Y4nm6JyELgEuBaDd9Ba2PxfIFY5/x/cwOrRWRYSKPqgiWOPiQigqcPfpOqPhDqeLqiqj9QVbeqjsJTtP2nqobtN2JVrQTKRGSCs2k2UBLCkLpTCpwpIv2cv4vZhHEx37EE+Kpz/6vAyyGMpVsiMgdPV+tlqlof6ng6o6obVHWIqo5y/r+VA9Odv+mwZImjb50FfAXPt/e1zm1uqIOKIrcDT4nIeuA04L9CHE+nnJbRc8BqYAOe/4thM+WEiDwDvA9MEJFyEbkR+AVwgYhsxdNi+kUoY/TWSbz/B6QBrzv/134f0iAdncQaUWzKEWOMMX6xFocxxhi/WOIwxhjjF0scxhhj/GKJwxhjjF8scRhjjPGLJQ5jwpiIfD4SZiY2scUShzHGGL9Y4jAmAETkOhH5yBlo9gdnHZPDIvJrZ82NN0Uky9n3NBH5wGudiIHO9nEi8oaIrBOR1SIy1jn9AK91Rp5yRpobEzKWOIzpJRHJBeYBZ6nqaUALcC3QHyhS1cnA28BPnEOeAL7vrBOxwWv7U8BDqpqPZ96qtplopwHfBiYBY/DMQGBMyCSEOgBjosBs4HSg0GkMpOKZALAVeNbZ56/AC866IRmq+raz/XHgbyKSBmSr6osAqtoA4JzvI1Utd35eC4wCVgb/ZRnTMUscxvSeAI+r6gkrzInIj9vt19P5fY553W/B/t+aELOuKmN6703gKhEZAsfX5j4Fz/+vq5x9vgysVNUa4KCIzHK2fwV421kRslxErnDOkeys02BM2LFvLsb0kqqWiMjdwGsiEgc0AbfiWUxqpvPYXjx1EPBMSf57JzFsB25wtn8F+IOI3Oec4+o+fBnG+MxmxzUmSETksKoOCHUcxgSadVUZY4zxi7U4jDHG+MVaHMYYY/xiicMYY4xfLHEYY4zxiyUOY4wxfrHEYYwxxi//H9wvRhbkaqqQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}